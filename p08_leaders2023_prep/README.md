# Поиск одинаковых товаров (подготовка к хакатону ЛЦТ 2023)
Проект завершён в мае 2023

Расписание хакатона позволяло зарегистрироваться и выбрать задачу заранее, поэтому на момент формирования команды мы уже знали, что будем решать задачу от компании OZON по поиску одинаковых товаров в парах. С момента регистрации и до старта у нас было около месяца на подготовку. Для проверки идей и обучения моделей использовался доработанный датасет из предыдущего соревнования от KazanExpress. В процессе подготовки каждый участник команды занимался своей частью исследований и делился результатами работы на регулярных общих созвонах.

Основной моей задачей, помимо детального изучения текстовых моделей BERT, Word2Vec, а также мультимодальной модели CLIP, сопоставляющей изображения и текстовые подписи к ним, было изучение оригинальной модели RTE (Recognizing Textual Entailment) с семантическими и лексическими признаками, которую представили авторы [статьи](https://arxiv.org/abs/2210.09723) на сайте arxiv.org, а также генерация признаков модели для использования в задаче по определению одинаковых товаров

## Вкратце о модели RTE:
Данная модель из семейства NLP-моделей служит для распознавания причинно-следственной связи между двумя текстами, когда один фрагмент текста, называемый "гипотезой" (H),  может быть выведен из другого фрагмента текста, называемого "текстом" (T). К примеру для текста Т = "Мать кормит ребенка молоком" гипотеза Н = "Младенец пьёт молоко" является истинным утверждением, то есть логическим следствием (Entailment). А гипотеза Н = "Человек ест рис" таковым не является (Neutral)
- Одна из отличительных особенностей метода, описанного в статье, заключается в том, что для выявления причинно-следственной связи между двумя текстами используются и лексические, и семантические признаки, включая такие, как:
  - Поэлементный вектор Манхэттенских расстояний (EMDV)
  - Среднее значение EMDV
  - Оценка сходства по Жаккару (JAC)
  - Сходство на основе мешка слов  (BoW)
  - Оценка семантического сходства (STS) на основе BERT
- Другая особенность метода заключалась в извлечении семантики текста путем поэлементного сложения векторов слов в единый вектор текста на основании порога вхождения. То есть, не каждый, а только значимый элемент вектора слова попадает в результирующий вектор текста

## Цели
На сегодняшний день готовой реализации данной модели в открытом доступе нет, поэтому было принято решение реализовать метод и идеи авторов статьи с нуля и сгенерировать все вышеперечисленные признаки для нашей задачи

## Результаты
1. Поэлементный вектор Манхэттенских расстояний (EMDV). Для извлечения векторов слов использовалась модель word2vec, предобученная на НКРЯ и русскоязычной Википедии за 2019 год с размерностью выходного вектора 300. Был полностью реализован предложенный авторами статьи алгоритм порогового поэлементного складывания векторов слов в единый вектор текста. В рамках нашей задачи векторы рассчитывались для текстов первого и второго товаров в паре, далее вычислялся модуль их разности — поэлементный вектор Манхэттенского расстояния
2. Среднее значение EMDV. Для каждой записи было вычислено среднее значение элементов вектора Манхэттенского расстояния
3. Оценка сходства по Жаккару (JAC). Данный признак оценивает сходство пары текстов, чтобы определить, какие слова являются общими, а какие уникальными. Фактически это отношение количества слов, общих для обоих текстов, к общему количеству слов в обоих текстах: len(T1 ∩ T2) / len(T1 ∪ T2)
4. Сходство на основе мешка слов (BoW). Мешок слов BoW — это векторное представление корпуса из нескольких текстов, где размерность каждого вектора — это количество уникальных слов, существующих в корпусе из нескольких текстов, а значение каждого вектора — частота слов в каждом тексте корпуса. Применительно к нашей задаче, каждая запись датафрейма содержит корпус из двух текстов. Для каждого текста вычисляются векторы, а затем вычисляется косинусная близость этих векторов
5. Оценка семантического сходства (STS) на основе BERT. Для вычисления семантической оценки сходства двух текстов (STS) используется предварительно обученная модель BERT. Семантический вектор каждого текста авторами метода предлагается складывать поэлементно из семантических векторов составляющих его слов. Тогда оценка STS вычисляется как косинусное сходство между векторами двух текстов

## Стек
python, pandas, numpy, nltk, pymorphy2, sklearn, gensim, torch, transformers
