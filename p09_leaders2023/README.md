# Поиск одинаковых товаров
Проект завершён в мае 2023

## В ходе проекта:
- оптимизация: спарс-матрицы, заполнение батчами и т.п.

<br>

## Описание
данные (описание, атрибуты, изображения)
сложности
распределение задач

## Цели
построить модель на признаках атрибутов

## Результаты и выводы
Модель включает два основных этапа: подготовка признаков из атрибутов товаров и непосредственно процесс обучения модели на них и получение предиктов

1. Подготовка признаков (ноутбук: ft02_get_features.ipynb)  attr01_get_features.ipynb

При обработке столбца с атрибутами товаров из обучающей выборки всего было получено 1447 уникальных атрибута. Значения атрибутов представляют собой списки строковых данных, в большинстве случаев состоящие из одного элемента-атрибута, реже – из нескольких элементов в списке

В качестве признаков используются совпадения, несовпадения и частичные совпадения в векторе из 1447 атрибутов, которые обозначаются определенными числовыми значениями, например, 1, 0.1, 0.5. Частичное совпадение имеет место, когда хотя бы у одного из товаров список значений для конкретного рассматриваемого атрибута состоит из 2 или более элементов и они пересекаются со значениями в списке атрибута второго товара в паре. В случаях, когда конкретного атрибута нет у сравниваемых товаров, или у одного товара есть, а у другого нет, в векторе признаков проставляются нули

2. Обучение и предикты модели (ноутбук: ft02_attr04.ipynb) переименовать в attr02_model.ipynb

Первичный исследовательский анализ показал, что разные категории 3-го уровня довольно сильно различаются по множеству параметров – по количеству сэмплов в train и test, по распределению таргета в train, и конечно по атрибутам, характерным для данной категории

Для того чтобы помочь модели разделять классы, для каждого признака рассчитывается "коэффициент значимости", который "подсвечивает" для модели случаи, на которые нужно обратить внимание. Например, в нулевом классе несовпадения атрибутов являются очень важным фактором, а совпадения атрибутов – наоборот, незначительным, на который не стоит обращать внимание (как впрочем в какой-то мере и совпадения атрибутов в первом классе). Таким образом, для каждой пары товаров исходный вектор признаков (длиной 1447) умножается на factor – вектор коэффициентов для каждого признака, подобранный в результате исследования и анализа их влияния на модель

Для того чтобы модель более прицельно могла классифицировать пары товаров, она обучалась отдельно на каждой категории 3го уровня. Далее предикты каждой категории объединялись в единый вектор предиктов. В качестве моделей для каждой категории была применена модель градиентного бустинга LightGBM

## Стек
python, pandas, ???

<br><br>






